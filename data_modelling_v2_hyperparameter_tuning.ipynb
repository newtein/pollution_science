{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9dd178364bfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mast\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mliteral_eval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from ast import literal_eval\n",
    "from numpy import nan\n",
    "import xgboost\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from fancyimpute import KNN\n",
    "import missingno as msno\n",
    "from copy import deepcopy\n",
    "import impyute.imputation.cs.mice as mice_imputation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score, explained_variance_score, median_absolute_error\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "pd.set_option('display.max_columns', 120)\n",
    "pd.set_option('display.max_rows', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading https://files.pythonhosted.org/packages/2e/bd/ad3a963b630fa3ee72d1a672fd207263fa0a18113688273afe8298293535/xgboost-0.82.tar.gz (665kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Cache entry deserialization failed, entry ignored\n",
      "No files/directories in c:\\users\\admini~1\\appdata\\local\\temp\\pip-build-qmacud\\xgboost\\pip-egg-info (from PKG-INFO)\n",
      "You are using pip version 9.0.1, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_actual, y_pred):\n",
    "    y_actual = y_actual['lifespan'].tolist()\n",
    "    y_pred = [i[0] if type(i) == list else i for i in y_pred.tolist()]\n",
    "    return (np.sum([np.abs((i-j)/i) for i,j in zip(y_actual, y_pred)])*100)/len(y_actual)\n",
    "\n",
    "def regression_report(y_true, y_pred):\n",
    "    ev = explained_variance_score(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    try:\n",
    "        msle = mean_squared_log_error(y_true, y_pred)\n",
    "    except:\n",
    "        msle = \"error\"\n",
    "    medal = median_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape_score = mape(y_true, y_pred)\n",
    "    response = {\n",
    "        \"Explained Variance\": ev,\n",
    "        \"Mean Squared Error\": mse,\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"Mean Squared Log Error\": msle,\n",
    "        \"Median Absolute Error\": medal,\n",
    "        \"MAPE\": mape_score,\n",
    "        \"r2_score\": r2,\n",
    "        \"RMSE\": mse**0.5\n",
    "    }\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"output/NAG_DETAILS_v8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete = [\"nag_name\", \"ideology(s)\",'objective(s)']\n",
    "df.drop(delete, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['nagcode_1', 'lifespan'], axis=1)\n",
    "y = df[['lifespan']]\n",
    "# X_complete = mice_imputation(X.values)\n",
    "X_complete = KNN(k=4).fit_transform(X.values)\n",
    "\n",
    "X = pd.DataFrame(X_complete, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    " \"learning_rate\"    : [0.0001, 0.005, 0.01, 0.025, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.5 ] ,\n",
    " \"max_depth\"        : [ 3, 4, 5, 6, 7, 8, 10],\n",
    " \"min_child_weight\" : [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ],\n",
    " \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4, 0.5, 0.6, 0.7 ],\n",
    " \"colsample_bytree\" : [ 0.1, 0.3, 0.4, 0.5 , 0.7, 0.8 ],\n",
    "  \"n_estimators\": [100, 150, 200, 250, 300, 350, 400],\n",
    "  \"sub_sample\": [1, 0.8]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scorer = make_scorer(mape, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_search=RandomizedSearchCV(regressor,param_distributions=params,\n",
    "                           n_iter=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           n_jobs=6,\n",
    "                           cv=300,\n",
    "                           verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 300 folds for each of 5 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=6)]: Done 500 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 1140 tasks      | elapsed:  3.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250.23839664459229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 1500 out of 1500 | elapsed:  4.2min finished\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "random_search.fit(X_train,y_train)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'gamma': 0.2,\n",
       " 'learning_rate': 0.25,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 9,\n",
       " 'n_estimators': 100,\n",
       " 'sub_sample': 1}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Explained Variance': 0.9888478627061943,\n",
       "  'MAPE': 23.517789303097484,\n",
       "  'Mean Absolute Error': 0.9458890024582761,\n",
       "  'Mean Squared Error': 1.6426317339661558,\n",
       "  'Mean Squared Log Error': 'error',\n",
       "  'Median Absolute Error': 0.7377566993236542,\n",
       "  'RMSE': 1.2816519550822507,\n",
       "  'r2_score': 0.9888478578820806},\n",
       " {'Explained Variance': 0.7599811656505073,\n",
       "  'MAPE': 86.34369262683049,\n",
       "  'Mean Absolute Error': 4.126031720443912,\n",
       "  'Mean Squared Error': 40.25715697158024,\n",
       "  'Mean Squared Log Error': 'error',\n",
       "  'Median Absolute Error': 2.964641571044922,\n",
       "  'RMSE': 6.344852793531166,\n",
       "  'r2_score': 0.7599702889575255})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor(**{'colsample_bytree': 0.5,\n",
    " 'gamma': 0.2,\n",
    " 'learning_rate': 0.25,\n",
    " 'max_depth': 3,\n",
    " 'min_child_weight': 9,\n",
    " 'n_estimators': 100,\n",
    " 'sub_sample': 1})\n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "Y_pred=model.predict(X_test)\n",
    "Y_pred_train=model.predict(X_train)\n",
    "\n",
    "regression_report(y_train, Y_pred_train),regression_report(y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open(\"output/weight.json\", \"rb\")\n",
    "weights = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'gamma': 0.1,\n",
       " 'learning_rate': 0.025,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 10,\n",
       " 'n_estimators': 350}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weight_string(weight_dict, config_headers):\n",
    "    temp=[]\n",
    "    for i in config_headers:\n",
    "        temp.append(\"{}: {}\".format(i, weight_dict.get(i)))\n",
    "    return \",\\n\".join(temp)\n",
    "\n",
    "def make_report_string(weight_dict, config_headers, alias):\n",
    "    temp=[]\n",
    "    if 'sub_sample' not in weight_dict:\n",
    "        weight_dict.update({'sub_sample':1})\n",
    "    for i in config_headers:\n",
    "        temp.append(\"{}: {}\".format(alias.get(i,i), weight_dict.get(i)))\n",
    "    return \",\\n\".join(temp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model-III: Using Xgboost for regression.\n",
    "\n",
    "\n",
    "'''\n",
    "import csv\n",
    "fw = open(\"output/configurations.csv\", \"w\")\n",
    "writer = csv.writer(fw)\n",
    "headers = [\"Configuration Name\", \"Xgboost Hyperparameters\", \"Regression Report Training\", \"Regression Report Testing\"]\n",
    "config_headers = [\"max_depth\", \"colsample_bytree\", \"gamma\", \"n_estimators\", \"learning_rate\", \"min_child_weight\", \"sub_sample\"]\n",
    "report_headers = [\"Explained Variance\",\"Mean Squared Error\",\"Mean Absolute Error\",\"Median Absolute Error\",\"MAPE\",  \"r2_score\", \"RMSE\"]\n",
    "alias = {'RMSE': 'Root Mean Squared Error', 'MAPE': 'Mean Absolute Percentage Error', 'r2_score': 'R^2 Score'}\n",
    "writer.writerow(headers)\n",
    "for index, weight in enumerate(weights):\n",
    "    col1 = \"Configuration-{}\".format(index+1)\n",
    "    col2 = make_weight_string(weight, config_headers)\n",
    "    model = XGBRegressor(**weight)\n",
    "    model.fit(X_train, y_train) \n",
    "\n",
    "    Y_pred=model.predict(X_test)\n",
    "    Y_pred_train=model.predict(X_train)\n",
    "\n",
    "    train_report = regression_report(y_train, Y_pred_train)\n",
    "    test_report = regression_report(y_test, Y_pred)\n",
    "    col3 = make_report_string(train_report, report_headers, alias)\n",
    "    col4 = make_report_string(test_report, report_headers, alias)\n",
    "    writer.writerow([col1, col2, col3, col4])\n",
    "\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
